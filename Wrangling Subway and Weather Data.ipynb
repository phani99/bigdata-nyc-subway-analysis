{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Wrangling Subway Data \n",
    "\n",
    "##Basic Exploration of Weather Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import pandasql\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save path to weather data\n",
    "path = os.path.realpath('data')\n",
    "weather_data = path + '/weather_underground.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Number of Rainy Days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def num_rainy_days(filename):\n",
    "    \n",
    "    weather_data = pandas.read_csv(filename)\n",
    "    \n",
    "    q = \"\"\"\n",
    "    SELECT\n",
    "    COUNT(*)\n",
    "    FROM \n",
    "    weather_data\n",
    "    WHERE\n",
    "    cast(rain as integer) > 0\n",
    "    \"\"\"\n",
    "    \n",
    "    #Execute your SQL command against the pandas frame\n",
    "    rainy_days = pandasql.sqldf(q.lower(), locals())\n",
    "    return rainy_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count(*)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count(*)\n",
       "0        10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rainy_days(path + \"/weather_underground.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  maxpressurem  maxdewptm  maxpressurei  maxdewpti  \\\n",
      "0  2011-05-01          1026          6         30.31         42   \n",
      "\n",
      "   since1julheatingdegreedaysnormal  heatingdegreedaysnormal  \\\n",
      "0                              4646                        8   \n",
      "\n",
      "   since1sepcoolingdegreedaysnormal  hail  since1julsnowfallm    ...      \\\n",
      "0                               NaN     0              157.23    ...       \n",
      "\n",
      "   precipi  snowfalli  since1jancoolingdegreedaysnormal  precipm  snowfallm  \\\n",
      "0        0          0                                13        0          0   \n",
      "\n",
      "   thunder  monthtodateheatingdegreedays  meantempi  maxvism  meantempm  \n",
      "0        0                             5         60       16         16  \n",
      "\n",
      "[1 rows x 70 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = pandas.read_csv(path + \"/weather_underground.csv\", nrows = 1)\n",
    "print data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Temp on Foggy and Non-Foggy Days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_temp_aggregate_by_fog(filename):\n",
    "\n",
    "    weather_data = pandas.read_csv(filename)\n",
    "\n",
    "    q = \"\"\"\n",
    "    SELECT\n",
    "    fog, cast(maxtempi as integer)\n",
    "    FROM\n",
    "    weather_data\n",
    "    GROUP BY\n",
    "    fog\n",
    "    \"\"\"\n",
    "    \n",
    "    #Execute your SQL command against the pandas frame\n",
    "    foggy_days = pandasql.sqldf(q.lower(), locals())\n",
    "    return foggy_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fog</th>\n",
       "      <th>cast(maxtempi as integer)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 0</td>\n",
       "      <td> 86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 1</td>\n",
       "      <td> 81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fog  cast(maxtempi as integer)\n",
       "0    0                         86\n",
       "1    1                         81"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_temp_aggregate_by_fog(weather_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Mean Temp on Weekends "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avg_weekend_temperature(filename):\n",
    "   \n",
    "    weather_data = pandas.read_csv(filename)\n",
    "\n",
    "    q = \"\"\"\n",
    "    SELECT avg(cast (meantempi as integer))\n",
    "    FROM weather_data\n",
    "    WHERE cast (strftime('%w', date) as integer) == 0\n",
    "    OR cast (strftime('%w', date) as integer) == 6\n",
    "    \"\"\"\n",
    "    \n",
    "    #Execute your SQL command against the pandas frame\n",
    "    mean_temp_weekends = pandasql.sqldf(q.lower(), locals())\n",
    "    return mean_temp_weekends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg(cast (meantempi as integer))</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 65.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg(cast (meantempi as integer))\n",
       "0                         65.111111"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_weekend_temperature(weather_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Mean Temp on Rainy Days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def avg_min_temperature(filename):\n",
    "\n",
    "    weather_data = pandas.read_csv(filename)\n",
    "\n",
    "    q = \"\"\"\n",
    "    SELECT avg(cast (mintempi as integer))\n",
    "    FROM weather_data['mintempi']\n",
    "    WHERE rain = 1\n",
    "    AND cast (mintempi as integer) > 55\n",
    "    \"\"\"\n",
    "    \n",
    "    #Execute your SQL command against the pandas frame\n",
    "    avg_min_temp_rainy = pandasql.sqldf(q.lower(), locals())\n",
    "\n",
    "    return avg_min_temp_rainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg(cast (mintempi as integer))</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 61.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg(cast (mintempi as integer))\n",
       "0                            61.25"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_min_temperature(weather_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Wrangling Subway Data \n",
    "\n",
    "###Fixing Turnstile Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the data from the MTA website (http://web.mta.info/developers/turnstile.html), the data has numerous data points in each row of the text files:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_first_line_of_first_textfile(filepath):\n",
    "    \n",
    "    for file in os.listdir(filepath):\n",
    "        if file.endswith(\".txt\"):\n",
    "\n",
    "            infile = open(filepath+'/'+file)\n",
    "            first_line = infile.readline()\n",
    "            print first_line\n",
    "\n",
    "            break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IA002,R051,02-00-00,04-17-10,00:00:00,REGULAR,002704717,000928793,04-17-10,04:00:00,REGULAR,002704723,000928795,04-17-10,08:00:00,REGULAR,002704731,000928816,04-17-10,12:00:00,REGULAR,002704835,000928898,04-17-10,16:00:00,REGULAR,002705074,000928943,04-17-10,20:00:00,REGULAR,002705399,000928981,04-18-10,00:00:00,REGULAR,002705426,000928987,04-18-10,04:00:00,REGULAR,002705426,000928987              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_files_path = 'data/turnstile_data/raw_files/'\n",
    "read_first_line_of_first_textfile(raw_files_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper method to aggregate all text files \n",
    "def aggregate_text_files_from_path(path):\n",
    "    \n",
    "    textfiles = [] \n",
    "    \n",
    "    for file in os.listdir(path):\n",
    "\n",
    "        if file.endswith(\".txt\"):\n",
    "            textfiles.append(path+\"/\"+file)\n",
    "\n",
    "    return textfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_turnstile_data(filenames):\n",
    "    \n",
    "    for name in filenames:\n",
    "        with open(name) as r:\n",
    "            read = csv.reader(r)\n",
    "\n",
    "            parent_path = os.path.split(name)[0]\n",
    "            grandparent_path = os.path.split(parent_path)[0]\n",
    "            path = os.path.split(name)[1]\n",
    "            name = os.path.splitext(path)[0]\n",
    "            \n",
    "            newpath = grandparent_path+\"/updated_raw_files/\" \n",
    "            if not os.path.exists(newpath): os.makedirs(newpath) \n",
    "                        \n",
    "            with open(newpath+'updated_'+name+'.txt', 'wb') as f:\n",
    "                writer = csv.writer(f)\n",
    "            \n",
    "                for row in read:                 \n",
    "                    writer.writerows([row[:3]+row[x:x+5] for x in range(3,len(row),5)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_file = os.path.realpath('data/turnstile_data/raw_files/')\n",
    "\n",
    "filenames = aggregate_text_files_from_path(data_file)\n",
    "\n",
    "fix_turnstile_data(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####Check the first updated file for changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IA002,R051,02-00-00,04-17-10,00:00:00,REGULAR,002704717,000928793\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "updated_file_path = 'data/turnstile_data/updated_raw_files'\n",
    "read_first_line_of_first_textfile(updated_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Combining Turnstile Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_master_csv_turnstile_file(filenames):\n",
    "    \n",
    "    output_file = None \n",
    "    # create an output file in the parent directory of the first file \n",
    "    for name in filenames:\n",
    "        with open(name) as r:\n",
    "            read = csv.reader(r)\n",
    "\n",
    "            parent_path = os.path.split(name)[0]\n",
    "            grandparent_path = os.path.split(parent_path)[0]\n",
    "            path = os.path.split(name)[1]\n",
    "            name = os.path.splitext(path)[0]\n",
    "            \n",
    "            newpath = grandparent_path+\"/combined_files/\" \n",
    "            if not os.path.exists(newpath): os.makedirs(newpath) \n",
    "            output_file = newpath+\"combined_from_\"+name+'.csv'  \n",
    "            break \n",
    "    \n",
    "    \n",
    "    with open(output_file, 'w') as master_file:\n",
    "       master_file.write('C/A,UNIT,SCP,DATEn,TIMEn,DESCn,ENTRIESn,EXITSn\\n')\n",
    "\n",
    "       for filename in filenames:\n",
    "\n",
    "            with open(filename, 'r') as data_file:\n",
    "                data_file.next()\n",
    "                # Gather the remaining data\n",
    "                for line in data_file:\n",
    "                    # Save read content to master_file\n",
    "                    master_file.write(line)\n",
    "                \n",
    "    return output_file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "updated_file_path = os.path.realpath('data/turnstile_data/updated_raw_files/')\n",
    "\n",
    "files_to_combine = aggregate_text_files_from_path(updated_file_path)\n",
    "\n",
    "combined_file = create_master_csv_turnstile_file(files_to_combine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####Check the combined file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C/A,UNIT,SCP,DATEn,TIMEn,DESCn,ENTRIESn,EXITSn\n",
      "\n",
      "next line IA002,R051,02-00-00,04-17-10,04:00:00,REGULAR,002704723,000928795\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f=open(combined_file)\n",
    "for line in f:\n",
    "    print line\n",
    "    nextline=f.next()\n",
    "    print \"next line\", nextline\n",
    "    break\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Filtering Irregular Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_by_regular(filename):\n",
    "    '''\n",
    "    This function should read the csv file located at filename into a pandas dataframe,\n",
    "    and filter the dataframe to only rows where the 'DESCn' column has the value 'REGULAR'.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    turnstile_data = pandas.read_csv(filename)\n",
    "    turnstile_data = pandas.DataFrame(turnstile_data)\n",
    "    return turnstile_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_filtered_by_regular = filter_by_regular(combined_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####Check filtered dataframe for changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     C/A  UNIT       SCP     DATEn     TIMEn    DESCn  ENTRIESn  EXITSn\n",
      "0  IA002  R051  02-00-00  04-17-10  04:00:00  REGULAR   2704723  928795\n",
      "1  IA002  R051  02-00-00  04-17-10  08:00:00  REGULAR   2704731  928816\n",
      "2  IA002  R051  02-00-00  04-17-10  12:00:00  REGULAR   2704835  928898\n",
      "3  IA002  R051  02-00-00  04-17-10  16:00:00  REGULAR   2705074  928943\n",
      "4  IA002  R051  02-00-00  04-17-10  20:00:00  REGULAR   2705399  928981\n"
     ]
    }
   ],
   "source": [
    "print df_filtered_by_regular.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###Get Hourly Entries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hourly_entries(df):\n",
    "\n",
    "    '''\n",
    "    1) Create a new column called ENTRIESn_hourly\n",
    "    2) Assign to the column the difference between ENTRIESn of the current row \n",
    "    and the previous row. If there is any NaN, fill/replace it with 1.\n",
    "    '''\n",
    " \n",
    "    df['ENTRIESn_hourly'] = df['ENTRIESn'] - df['ENTRIESn'].shift(1)\n",
    "    df.fillna(1, inplace=True)    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_get_hourly_entries = get_hourly_entries(df_filtered_by_regular)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Get Hourly Exits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hourly_exits(df):\n",
    "    '''\n",
    "    1) Create a new column called EXITSn_hourly\n",
    "    2) Assign to the column the difference between EXITSn of the current row \n",
    "    and the previous row. If there is any NaN, fill/replace it with 0.\n",
    "    '''\n",
    "    \n",
    "    df['EXITSn_hourly'] = df['EXITSn'] - df['EXITSn'].shift(1)\n",
    "    df.fillna(0, inplace=True)   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_get_hourly_entries_and_exits = get_hourly_exits(df_get_hourly_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####Check filtered dataframe for changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     C/A  UNIT       SCP     DATEn     TIMEn    DESCn  ENTRIESn  EXITSn  \\\n",
      "0  IA002  R051  02-00-00  04-17-10  04:00:00  REGULAR   2704723  928795   \n",
      "1  IA002  R051  02-00-00  04-17-10  08:00:00  REGULAR   2704731  928816   \n",
      "2  IA002  R051  02-00-00  04-17-10  12:00:00  REGULAR   2704835  928898   \n",
      "3  IA002  R051  02-00-00  04-17-10  16:00:00  REGULAR   2705074  928943   \n",
      "4  IA002  R051  02-00-00  04-17-10  20:00:00  REGULAR   2705399  928981   \n",
      "\n",
      "   ENTRIESn_hourly  EXITSn_hourly  \n",
      "0                1              0  \n",
      "1                8             21  \n",
      "2              104             82  \n",
      "3              239             45  \n",
      "4              325             38  \n"
     ]
    }
   ],
   "source": [
    "print df_get_hourly_entries_and_exits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Time to Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def time_to_hour(time):\n",
    "\n",
    "    \n",
    "    hour = int(time.split(':')[0])\n",
    "    return hour\n",
    "\n",
    "def get_hours(df):\n",
    "\n",
    "    hours_converted = []\n",
    "    for hours in df['TIMEn']:\n",
    "\n",
    "        hours_converted.append(time_to_hour(hours))\n",
    "\n",
    "    df['HOURSn'] = hours_converted\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_get_hours = get_hours(df_get_hourly_entries_and_exits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Reformat Subway Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime \n",
    "def reformat_subway_dates(date):\n",
    "\n",
    "    date_formatted = str(datetime.datetime.strptime(date, \"%m-%d-%y\"))[:10]\n",
    "    return date_formatted\n",
    "\n",
    "def get_dates(df):\n",
    "\n",
    "    dates_converted = []\n",
    "\n",
    "    for date in df['DATEn']:\n",
    "\n",
    "        dates_converted.append(reformat_subway_dates(date))\n",
    "\n",
    "    df['DATEn'] = dates_converted\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_get_dates = get_dates(df_get_hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####Check filtered dataframe for changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     C/A  UNIT       SCP       DATEn     TIMEn    DESCn  ENTRIESn  EXITSn  \\\n",
      "0  IA002  R051  02-00-00  2010-04-17  04:00:00  REGULAR   2704723  928795   \n",
      "1  IA002  R051  02-00-00  2010-04-17  08:00:00  REGULAR   2704731  928816   \n",
      "2  IA002  R051  02-00-00  2010-04-17  12:00:00  REGULAR   2704835  928898   \n",
      "3  IA002  R051  02-00-00  2010-04-17  16:00:00  REGULAR   2705074  928943   \n",
      "4  IA002  R051  02-00-00  2010-04-17  20:00:00  REGULAR   2705399  928981   \n",
      "\n",
      "   ENTRIESn_hourly  EXITSn_hourly  HOURSn  \n",
      "0                1              0       4  \n",
      "1                8             21       8  \n",
      "2              104             82      12  \n",
      "3              239             45      16  \n",
      "4              325             38      20  \n"
     ]
    }
   ],
   "source": [
    "print df_get_dates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Save the combined file as a new csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_new_path(home, new_path):\n",
    "    newpath = home+new_path\n",
    "    if not os.path.exists(newpath): os.makedirs(newpath) \n",
    "        \n",
    "    return newpath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "updated_combined_files_path = make_new_path(path, '/turnstile_data/updated_combined_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "updated_data = df_get_dates\n",
    "updated_data.to_csv(updated_combined_files_path+'/updated_combined_file.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
